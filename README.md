# Network representations learning
Hyper-Representations as Generative Models: Sampling Unseen Neural Network Weights
https://arxiv.org/abs/2209.14733

Learning to Learn with Generative Models of Neural Network Checkpoints
https://arxiv.org/abs/2209.12892


Permutation Equivariant Neural Functionals
https://arxiv.org/pdf/2302.14040.pdf

NERN - LEARNING NEURAL REPRESENTATIONS FOR
NEURAL NETWORKS
https://arxiv.org/pdf/2212.13554.pdf

Equivariant Tensor Networks
https://arxiv.org/pdf/2304.08226.pdf


# Domain generalization
Diverse Weight Averaging for Out-of-Distribution Generalization
https://arxiv.org/abs/2205.09739


Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time
https://arxiv.org/abs/2203.05482

Zoo-Tuning: Adaptive Transfer from a Zoo of Models 
https://arxiv.org/abs/2106.15434


# Fine-tuning and model distillation
Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution
https://arxiv.org/abs/2202.10054

Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time
https://arxiv.org/abs/2203.05482

# Neural architecture search

Can GPT-4 Perform Neural Architecture Search?
https://arxiv.org/abs/2304.10970

# Others

Neural Discrete Representation Learning
https://arxiv.org/abs/1711.00937

TAMING TRANSFORMERS FOR HIGH-RESOLUTION IMAGE SYNTHESIS (A.K.A #VQGAN)
https://compvis.github.io/taming-transformers/

Denoising Diffusion Probabilistic Models
https://arxiv.org/abs/2006.11239

Denoising Diffusion Implicit Models
https://arxiv.org/abs/2010.02502

Denoising Diffusion Implicit Models
https://arxiv.org/abs/2010.02502

High-Resolution Image Synthesis with Latent Diffusion Models
https://arxiv.org/abs/2112.10752














